{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orthogonal Fine-Tuning (OFT) Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Orthogonal Fine-Tuning (OFT) is a parameter-efficient fine-tuning (PEFT) technique that adapts pre-trained models by applying orthogonal transformations to weight matrices. Unlike other PEFT methods like LoRA, OFT preserves the hyperspherical energy – the geometric relationships between neuron activations – ensuring stable and efficient adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Orthogonal Matrices\n",
    "\n",
    "An orthogonal matrix Q satisfies: Q^T Q = QQ^T = I\n",
    "\n",
    "Key properties:\n",
    "- Preserves distances and angles\n",
    "- Preserves norms: ||Qx|| = ||x||\n",
    "- Represents rotations and reflections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import special_ortho_group\n",
    "\n",
    "# Generate a random orthogonal matrix\n",
    "def generate_orthogonal_matrix(dim):\n",
    "    \"\"\"Generate a random orthogonal matrix using QR decomposition\"\"\"\n",
    "    random_matrix = np.random.randn(dim, dim)\n",
    "    q, r = np.linalg.qr(random_matrix)\n",
    "    return q\n",
    "\n",
    "# Verify orthogonality\n",
    "Q = generate_orthogonal_matrix(4)\n",
    "print(\"Random orthogonal matrix Q:\")\n",
    "print(Q)\n",
    "print(\"\\nQ^T @ Q (should be identity):\")\n",
    "print(np.round(Q.T @ Q, 4))\n",
    "print(\"\\nDeterminant (should be ±1):\", np.linalg.det(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualizing Orthogonal Transformations\n",
    "\n",
    "Let's visualize how orthogonal transformations preserve geometric relationships while rotating the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample 2D data\n",
    "np.random.seed(42)\n",
    "n_points = 100\n",
    "original_data = np.random.randn(n_points, 2)\n",
    "\n",
    "# Create a 2D rotation matrix (orthogonal)\n",
    "theta = np.pi / 4  # 45 degrees\n",
    "rotation_matrix = np.array([\n",
    "    [np.cos(theta), -np.sin(theta)],\n",
    "    [np.sin(theta), np.cos(theta)]\n",
    "])\n",
    "\n",
    "# Apply orthogonal transformation\n",
    "transformed_data = original_data @ rotation_matrix.T\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original data\n",
    "axes[0].scatter(original_data[:, 0], original_data[:, 1], alpha=0.6)\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].set_xlim(-4, 4)\n",
    "axes[0].set_ylim(-4, 4)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# Transformed data\n",
    "axes[1].scatter(transformed_data[:, 0], transformed_data[:, 1], alpha=0.6, color='orange')\n",
    "axes[1].set_title('After Orthogonal Transformation')\n",
    "axes[1].set_xlim(-4, 4)\n",
    "axes[1].set_ylim(-4, 4)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_aspect('equal')\n",
    "\n",
    "# Overlay comparison\n",
    "axes[2].scatter(original_data[:, 0], original_data[:, 1], alpha=0.6, label='Original')\n",
    "axes[2].scatter(transformed_data[:, 0], transformed_data[:, 1], alpha=0.6, color='orange', label='Transformed')\n",
    "axes[2].set_title('Comparison: Rotation Preserves Structure')\n",
    "axes[2].set_xlim(-4, 4)\n",
    "axes[2].set_ylim(-4, 4)\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_aspect('equal')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Verify preservation of distances\n",
    "original_distances = np.linalg.norm(original_data[0] - original_data[1])\n",
    "transformed_distances = np.linalg.norm(transformed_data[0] - transformed_data[1])\n",
    "print(f\"Distance between first two points:\")\n",
    "print(f\"  Original: {original_distances:.4f}\")\n",
    "print(f\"  Transformed: {transformed_distances:.4f}\")\n",
    "print(f\"  Preserved: {np.isclose(original_distances, transformed_distances)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. OFT Core Implementation\n",
    "\n",
    "The key insight of OFT is to parameterize weight updates as:\n",
    "\n",
    "**W' = W × R**\n",
    "\n",
    "Where:\n",
    "- W is the original pre-trained weight matrix\n",
    "- R is an orthogonal matrix (learned during fine-tuning)\n",
    "- W' is the adapted weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OFTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Orthogonal Fine-Tuning layer implementation.\n",
    "    Applies an orthogonal transformation to the weight matrix.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, rank=16):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.rank = min(rank, min(in_features, out_features))\n",
    "        \n",
    "        # Pre-trained weights (frozen)\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.weight.requires_grad = False\n",
    "        \n",
    "        # Orthogonal transformation parameters\n",
    "        # We use Cayley parameterization for stable orthogonal updates\n",
    "        self.cayley_map = nn.Parameter(torch.zeros(self.rank, self.rank))\n",
    "        \n",
    "    def get_orthogonal_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute orthogonal matrix using Cayley transform:\n",
    "        R = (I - A)(I + A)^(-1)\n",
    "        where A is skew-symmetric\n",
    "        \"\"\"\n",
    "        # Make skew-symmetric\n",
    "        A = self.cayley_map - self.cayley_map.t()\n",
    "        I = torch.eye(self.rank, device=A.device)\n",
    "        \n",
    "        # Cayley transform\n",
    "        R = torch.linalg.solve(I + A, I - A)\n",
    "        return R\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get orthogonal transformation\n",
    "        R = self.get_orthogonal_matrix()\n",
    "        \n",
    "        # For simplicity, apply R to a subspace of the weight matrix\n",
    "        # In practice, this would be more sophisticated\n",
    "        W_adapted = self.weight.clone()\n",
    "        W_adapted[:self.rank, :self.rank] = self.weight[:self.rank, :self.rank] @ R\n",
    "        \n",
    "        return x @ W_adapted.t()\n",
    "\n",
    "# Example usage\n",
    "oft_layer = OFTLayer(128, 64, rank=16)\n",
    "input_tensor = torch.randn(32, 128)  # batch_size=32, in_features=128\n",
    "output = oft_layer(input_tensor)\n",
    "print(f\"Input shape: {input_tensor.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in oft_layer.parameters() if p.requires_grad)}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in oft_layer.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparing OFT with LoRA\n",
    "\n",
    "Let's implement a simple comparison between OFT and LoRA to understand their differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Low-Rank Adaptation (LoRA) layer for comparison.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, rank=16):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.rank = rank\n",
    "        \n",
    "        # Pre-trained weights (frozen)\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
    "        self.weight.requires_grad = False\n",
    "        \n",
    "        # LoRA parameters\n",
    "        self.lora_A = nn.Parameter(torch.randn(rank, in_features) * 0.01)\n",
    "        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Original transformation + low-rank update\n",
    "        return x @ self.weight.t() + x @ self.lora_A.t() @ self.lora_B.t()\n",
    "\n",
    "# Compare parameter efficiency\n",
    "in_features, out_features = 512, 256\n",
    "rank = 16\n",
    "\n",
    "oft_layer = OFTLayer(in_features, out_features, rank)\n",
    "lora_layer = LoRALayer(in_features, out_features, rank)\n",
    "\n",
    "oft_params = sum(p.numel() for p in oft_layer.parameters() if p.requires_grad)\n",
    "lora_params = sum(p.numel() for p in lora_layer.parameters() if p.requires_grad)\n",
    "total_params = in_features * out_features\n",
    "\n",
    "print(\"Parameter Efficiency Comparison:\")\n",
    "print(f\"Original layer parameters: {total_params:,}\")\n",
    "print(f\"OFT trainable parameters: {oft_params:,} ({oft_params/total_params*100:.2f}%)\")\n",
    "print(f\"LoRA trainable parameters: {lora_params:,} ({lora_params/total_params*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperspherical Energy Preservation\n",
    "\n",
    "A key advantage of OFT is preserving hyperspherical energy, which maintains the angular relationships between features. Let's demonstrate this concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hyperspherical_energy(features):\n",
    "    \"\"\"\n",
    "    Compute hyperspherical energy as the sum of pairwise angular similarities.\n",
    "    Lower energy indicates more uniform distribution on the hypersphere.\n",
    "    \"\"\"\n",
    "    # Normalize features to unit sphere\n",
    "    normalized = features / (torch.norm(features, dim=-1, keepdim=True) + 1e-8)\n",
    "    \n",
    "    # Compute pairwise cosine similarities\n",
    "    similarities = torch.matmul(normalized, normalized.t())\n",
    "    \n",
    "    # Hyperspherical energy (Riesz s-energy with s=1)\n",
    "    n = features.shape[0]\n",
    "    mask = 1 - torch.eye(n)\n",
    "    energy = -torch.sum(torch.log(1 - similarities + 1e-8) * mask) / (n * (n - 1))\n",
    "    \n",
    "    return energy\n",
    "\n",
    "# Generate sample features\n",
    "torch.manual_seed(42)\n",
    "n_samples = 50\n",
    "n_features = 64\n",
    "\n",
    "# Original features\n",
    "original_features = torch.randn(n_samples, n_features)\n",
    "\n",
    "# Apply different transformations\n",
    "# 1. Orthogonal transformation (OFT-style)\n",
    "Q = torch.tensor(generate_orthogonal_matrix(n_features), dtype=torch.float32)\n",
    "oft_features = original_features @ Q.t()\n",
    "\n",
    "# 2. Random transformation (non-orthogonal)\n",
    "random_matrix = torch.randn(n_features, n_features) * 0.5 + torch.eye(n_features)\n",
    "random_features = original_features @ random_matrix.t()\n",
    "\n",
    "# 3. Low-rank update (LoRA-style)\n",
    "A = torch.randn(16, n_features) * 0.1\n",
    "B = torch.randn(n_features, 16) * 0.1\n",
    "lora_features = original_features + original_features @ A.t() @ B.t()\n",
    "\n",
    "# Compute energies\n",
    "original_energy = compute_hyperspherical_energy(original_features)\n",
    "oft_energy = compute_hyperspherical_energy(oft_features)\n",
    "random_energy = compute_hyperspherical_energy(random_features)\n",
    "lora_energy = compute_hyperspherical_energy(lora_features)\n",
    "\n",
    "print(\"Hyperspherical Energy Comparison:\")\n",
    "print(f\"Original features: {original_energy:.4f}\")\n",
    "print(f\"After OFT (orthogonal): {oft_energy:.4f} (change: {abs(oft_energy - original_energy):.4f})\")\n",
    "print(f\"After random transform: {random_energy:.4f} (change: {abs(random_energy - original_energy):.4f})\")\n",
    "print(f\"After LoRA update: {lora_energy:.4f} (change: {abs(lora_energy - original_energy):.4f})\")\n",
    "print(\"\\nOFT preserves hyperspherical energy best!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical OFT Module for Transformer Models\n",
    "\n",
    "Let's implement a more practical OFT module that can be integrated into transformer-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OFTModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Production-ready OFT module with block-diagonal structure for efficiency.\n",
    "    \"\"\"\n",
    "    def __init__(self, original_module, rank=16, num_blocks=4, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.original_module = original_module\n",
    "        self.rank = rank\n",
    "        self.num_blocks = num_blocks\n",
    "        self.alpha = alpha  # Scaling factor for the adaptation\n",
    "        \n",
    "        # Get dimensions from original module\n",
    "        if isinstance(original_module, nn.Linear):\n",
    "            self.in_features = original_module.in_features\n",
    "            self.out_features = original_module.out_features\n",
    "        else:\n",
    "            raise ValueError(\"OFT currently supports only Linear layers\")\n",
    "        \n",
    "        # Block size for block-diagonal structure\n",
    "        self.block_size = min(rank, min(self.in_features, self.out_features) // num_blocks)\n",
    "        \n",
    "        # Initialize block-diagonal orthogonal parameters\n",
    "        self.blocks = nn.ParameterList([\n",
    "            nn.Parameter(torch.zeros(self.block_size, self.block_size))\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Freeze original weights\n",
    "        for param in self.original_module.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def get_block_diagonal_orthogonal(self):\n",
    "        \"\"\"\n",
    "        Construct block-diagonal orthogonal matrix from individual blocks.\n",
    "        \"\"\"\n",
    "        device = self.blocks[0].device\n",
    "        total_size = self.block_size * self.num_blocks\n",
    "        R = torch.zeros(total_size, total_size, device=device)\n",
    "        \n",
    "        for i, block_param in enumerate(self.blocks):\n",
    "            # Apply Cayley transform to each block\n",
    "            A = block_param - block_param.t()\n",
    "            I = torch.eye(self.block_size, device=device)\n",
    "            block_R = torch.linalg.solve(I + A, I - A)\n",
    "            \n",
    "            # Place in block-diagonal structure\n",
    "            start = i * self.block_size\n",
    "            end = start + self.block_size\n",
    "            R[start:end, start:end] = block_R\n",
    "        \n",
    "        return R\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get original output\n",
    "        original_output = self.original_module(x)\n",
    "        \n",
    "        # Apply orthogonal adaptation to a subspace\n",
    "        R = self.get_block_diagonal_orthogonal()\n",
    "        adapted_weight = self.original_module.weight.clone()\n",
    "        \n",
    "        # Apply rotation to subspace of weights\n",
    "        subspace_size = R.shape[0]\n",
    "        if subspace_size <= min(self.out_features, self.in_features):\n",
    "            W_sub = adapted_weight[:subspace_size, :subspace_size]\n",
    "            adapted_weight[:subspace_size, :subspace_size] = W_sub @ R\n",
    "        \n",
    "        # Compute adapted output\n",
    "        adapted_output = nn.functional.linear(x, adapted_weight, self.original_module.bias)\n",
    "        \n",
    "        # Blend original and adapted outputs\n",
    "        return (1 - self.alpha) * original_output + self.alpha * adapted_output\n",
    "\n",
    "# Example: Applying OFT to a pre-trained linear layer\n",
    "original_layer = nn.Linear(256, 128)\n",
    "oft_adapted_layer = OFTModule(original_layer, rank=8, num_blocks=4, alpha=0.5)\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(16, 256)\n",
    "output = oft_adapted_layer(test_input)\n",
    "\n",
    "print(f\"OFT Module Configuration:\")\n",
    "print(f\"  Original layer: Linear({original_layer.in_features}, {original_layer.out_features})\")\n",
    "print(f\"  Block size: {oft_adapted_layer.block_size}\")\n",
    "print(f\"  Number of blocks: {oft_adapted_layer.num_blocks}\")\n",
    "print(f\"  Trainable parameters: {sum(p.numel() for p in oft_adapted_layer.parameters() if p.requires_grad)}\")\n",
    "print(f\"  Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Example with OFT\n",
    "\n",
    "Let's demonstrate how to train a model using OFT for a simple classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dataset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Generate synthetic classification data\n",
    "torch.manual_seed(42)\n",
    "n_samples = 1000\n",
    "n_features = 64\n",
    "n_classes = 10\n",
    "\n",
    "X = torch.randn(n_samples, n_features)\n",
    "y = torch.randint(0, n_classes, (n_samples,))\n",
    "\n",
    "# Split into train and test\n",
    "train_size = int(0.8 * n_samples)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define a simple model with OFT adaptation\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, use_oft=False):\n",
    "        super().__init__()\n",
    "        self.use_oft = use_oft\n",
    "        \n",
    "        # Create layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Apply OFT if requested\n",
    "        if use_oft:\n",
    "            self.fc1 = OFTModule(self.fc1, rank=8, num_blocks=2)\n",
    "            self.fc2 = OFTModule(self.fc2, rank=8, num_blocks=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create two models: one with OFT, one without\n",
    "model_oft = SimpleClassifier(n_features, 128, n_classes, use_oft=True)\n",
    "model_regular = SimpleClassifier(n_features, 128, n_classes, use_oft=False)\n",
    "\n",
    "# Count parameters\n",
    "oft_trainable = sum(p.numel() for p in model_oft.parameters() if p.requires_grad)\n",
    "regular_trainable = sum(p.numel() for p in model_regular.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Regular model trainable parameters: {regular_trainable:,}\")\n",
    "print(f\"OFT model trainable parameters: {oft_trainable:,}\")\n",
    "print(f\"Parameter reduction: {(1 - oft_trainable/regular_trainable)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, test_loader, epochs=10, lr=0.001):\n",
    "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_losses.append(epoch_loss / len(train_loader))\n",
    "        \n",
    "        # Testing\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "        accuracy = correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_losses[-1]:.4f}, Test Acc: {accuracy:.4f}\")\n",
    "    \n",
    "    return train_losses, test_accuracies\n",
    "\n",
    "# Train OFT model\n",
    "print(\"Training OFT Model:\")\n",
    "oft_losses, oft_accs = train_model(model_oft, train_loader, test_loader, epochs=10)\n",
    "\n",
    "# For comparison, we could also train the regular model\n",
    "# Note: In practice, OFT is used for fine-tuning pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advantages and Use Cases of OFT\n",
    "\n",
    "### Key Advantages:\n",
    "\n",
    "1. **Stability**: Orthogonal transformations prevent gradient explosion/vanishing\n",
    "2. **Parameter Efficiency**: Fewer trainable parameters than full fine-tuning\n",
    "3. **Geometric Preservation**: Maintains learned feature relationships\n",
    "4. **Better Generalization**: Less prone to overfitting on small datasets\n",
    "\n",
    "### Best Use Cases:\n",
    "\n",
    "- **Domain Adaptation**: When fine-tuning to a related but different domain\n",
    "- **Few-Shot Learning**: When training data is limited\n",
    "- **Multi-Task Learning**: Preserving shared representations across tasks\n",
    "- **Continual Learning**: Reducing catastrophic forgetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration: Stability comparison\n",
    "def analyze_gradient_flow(model, input_data, target):\n",
    "    \"\"\"\n",
    "    Analyze gradient magnitudes through the network.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "    loss = criterion(output, target)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Collect gradient norms\n",
    "    gradient_norms = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad and param.grad is not None:\n",
    "            grad_norm = param.grad.norm().item()\n",
    "            gradient_norms.append(grad_norm)\n",
    "            print(f\"{name}: gradient norm = {grad_norm:.6f}\")\n",
    "    \n",
    "    return gradient_norms\n",
    "\n",
    "# Create test data\n",
    "test_input = torch.randn(32, n_features)\n",
    "test_target = torch.randint(0, n_classes, (32,))\n",
    "\n",
    "print(\"Gradient Flow Analysis for OFT Model:\")\n",
    "print(\"=\"*50)\n",
    "grad_norms = analyze_gradient_flow(model_oft, test_input, test_target)\n",
    "print(f\"\\nAverage gradient norm: {np.mean(grad_norms):.6f}\")\n",
    "print(f\"Gradient variance: {np.var(grad_norms):.6f}\")\n",
    "print(\"\\nNote: OFT maintains stable gradients due to orthogonal constraints!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Orthogonal Fine-Tuning (OFT) represents a significant advancement in parameter-efficient fine-tuning:\n",
    "\n",
    "- **Preserves geometric structure** of pre-trained representations\n",
    "- **More stable training** compared to unconstrained methods\n",
    "- **Highly parameter-efficient** while maintaining model capacity\n",
    "- **Better suited** for tasks requiring preservation of learned features\n",
    "\n",
    "The orthogonal constraint ensures that fine-tuning rotates the feature space rather than arbitrarily distorting it, leading to more robust and generalizable adaptations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}